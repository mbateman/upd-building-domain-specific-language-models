{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e9f4206",
   "metadata": {},
   "source": [
    "# M1 Loading and Preparing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26f05c2",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The goal of this preliminary milestone is to load and preprocess the dataset. The raw text is noisy and we want to remove nonwords and non-ASCII characters, keep punctuation to a minimum, and reduce the overall vocabulary of the corpus.\n",
    "\n",
    "- Although this corpus is not as noisy as a text directly extracted from a social network (for example, Twitter or Facebook), it is still not as structured as academic papers or newspaper articles. Furthermore, the corpus displays some interesting particularities, such as the presence of HTML markup and LaTeX-formatted equations. The corpus is also rich in specific entities, names of theorems, and statistical test algorithms, and it mixes colloquial writing with more formally structured paragraphs.\n",
    "\n",
    "\n",
    "- The garbage-in, garbage-out golden rule of machine learning is also applicable to language models. Simply put, if we skip the preprocessing/cleaning part of the project, the vocabulary of our language model will be too vast and noisy to make any sense. Generated text, for instance, may mix in mathematical symbols with punctuation signs or random HTML tags and numbers. By reducing the volume of the corpus vocabulary, we increase the relevance and quality of the generated text and improve the reliability of sentence selection based on their respective probabilities. We also reduce the memory imprint of our code and its execution time.\n",
    "\n",
    "\n",
    "- Preprocessing the text to reduce noise and vocabulary size is an iterative process. You should start simple and further refine the preprocessing steps after building and evaluating your first language models.~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "553d6381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer, TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad111b6f",
   "metadata": {},
   "source": [
    "## Load the dataset into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd2b0dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/data/stackexchange_812k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd7ce3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 812132 entries, 0 to 812131\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   post_id     812132 non-null  int64  \n",
      " 1   parent_id   75535 non-null   float64\n",
      " 2   comment_id  553076 non-null  float64\n",
      " 3   text        812132 non-null  object \n",
      " 4   category    812132 non-null  object \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 31.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99bcadf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eliciting priors from experts</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is normality?</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What are some valuable Statistical Analysis op...</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assessing the significance of differences in d...</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learn...</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  parent_id  comment_id  \\\n",
       "0        1        NaN         NaN   \n",
       "1        2        NaN         NaN   \n",
       "2        3        NaN         NaN   \n",
       "3        4        NaN         NaN   \n",
       "4        6        NaN         NaN   \n",
       "\n",
       "                                                text category  \n",
       "0                      Eliciting priors from experts    title  \n",
       "1                                 What is normality?    title  \n",
       "2  What are some valuable Statistical Analysis op...    title  \n",
       "3  Assessing the significance of differences in d...    title  \n",
       "4  The Two Cultures: statistics vs. machine learn...    title  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95af6951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498456    S. Haykin, Adaptive Filter Theory, 5th Edition...\n",
       "89243     Understanding the violation of the independenc...\n",
       "15152     Confusion over lmer and p-values: how do p-val...\n",
       "15904     Is a large control sample better than a balanc...\n",
       "170280    <p>Figure 1 there clarifies things a bit. All ...\n",
       "649371    Fair enough, I agree/stand corrected. I still ...\n",
       "112754    <p>There are some angles on this to consider. ...\n",
       "810641                  Any question @RiturajSinghRathore ?\n",
       "120845    <p>Your example is a very good one because it ...\n",
       "66418     Question about notation of expectation operato...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b201a",
   "metadata": {},
   "source": [
    "## Use regular expressions to remove elements that are not words, such as HTML tags, LaTeX expressions, URLs, digits, and line returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "981ebe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML = \"<[^>]*>\"\n",
    "LATEX = \"\\$[^>]*\\$\"\n",
    "URLS = \"http\\S+\"\n",
    "CRS = \"[\\r\\n]+\"\n",
    "DIGITS = \"\\$[^>]*\\$\"\n",
    "SPACES = \"\\s\\s+\"\n",
    "PUNCT = '\"#$%&()*+/:;<=>@[\\\\]^_`{|}~”“'\n",
    "pattern = r\"[{}]\".format(PUNCT)\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = re.sub(HTML,' ', text)\n",
    "    text = re.sub(LATEX,' ', text)\n",
    "    text = re.sub(URLS,' ', text)\n",
    "    text = re.sub(CRS,' ', text)\n",
    "    text = re.sub(DIGITS,' ', text)\n",
    "    text = re.sub(pattern,' ', text)\n",
    "    text = re.sub(SPACES,' ', text)\n",
    "    text = re.sub(DIGITS,' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2cac22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Formulate hypotheses when'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text('Formulate hypotheses when $\\mu_A < \\mu_B$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ece878bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'See my response to a href'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text('See my response to <a href=\"https://stackoverflow.com/questions/2252144/datasets-for-running-statistical-analysis-on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cae6a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "May fit better under: http://stats.stackexchange.com/questions/1906/data-mining-conferences?\n",
      "--------------------\n",
      "$X$ is the mean of something and is distributed as $Exp(1)$ and Y is the actual value (i.e. not the mean) with parameter $X = x$ such that $Y | X = x$ is distributed as $Pois(X = x)$. I'll give my own answer right now and hopefully, you can confirm it.\n",
      "--------------------\n",
      "What result do you get if you just use a random forest regression model instead of the classifier and then regressor?\n"
     ]
    }
   ],
   "source": [
    "# Sample of comments\n",
    "for p in df[df.category == 'comment'].text.sample(3).values:\n",
    "  print('-' * 20)\n",
    "  print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e4d4341",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6302af1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Glen b and samooch and Marius The formula expansion of factor symbol factor time will include main effects for both symbol and time. Furthermore, the 0 will only change the labeling of the effects. Instead of an Intercept term you will see the estimates for interaction of the lowest levels for symbol and time. If you wanted to avoid estimating a main effect for time you would need to use factor symbol factor time\n",
      "--------------------\n",
      "I don't understand your question. Are you asking what does it mean if all variables are most strongly correlated with PC1?\n",
      "--------------------\n",
      "Yes, I didn't know the term eigenface but that's what they are when I have just one output neuron with 6 output neurons I still get faces but they are much more noisy .\n"
     ]
    }
   ],
   "source": [
    "# Post clean sample of comments\n",
    "for p in df[df.category == 'comment'].text.sample(3).values:\n",
    "  print('-' * 20)\n",
    "  print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a970bdf9",
   "metadata": {},
   "source": [
    "## Remove texts that contain blanks only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "936605ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812132"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "435cbb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1422"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.text.str.len() == 0].text.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0319346b",
   "metadata": {},
   "source": [
    "1422 out of 812132 entries have a zero length text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d07c3cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.text.str.len() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82ba2c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810710"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace21d07",
   "metadata": {},
   "source": [
    "## Remove texts that are extremely large or too short to add any information to the model. \n",
    "\n",
    "We want to keep paragraphs that contain at least a few words and remove the paragraphs that are composed of large numerical tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2fbdfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "df['tokens'] = df.text.apply(lambda t : tokenizer.tokenize(t.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f036c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n_tokens'] = df.tokens.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16b7e664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    810710.000000\n",
       "mean         63.246199\n",
       "std         122.586727\n",
       "min           1.000000\n",
       "25%          16.000000\n",
       "50%          36.000000\n",
       "75%          72.000000\n",
       "max       14835.000000\n",
       "Name: n_tokens, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.n_tokens.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f038227b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14835"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.n_tokens.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b543f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(791172, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df.n_tokens > 4) & (df.n_tokens < 5000)].reset_index(drop = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3274d6a",
   "metadata": {},
   "source": [
    "## Use a tokenizer to create a version of the original text that is a string of space-separated lowercase tokens. \n",
    "\n",
    "For instance,\n",
    "\n",
    "- Thank you!, This equation y = ax + by=ax+b, is very helpful.\n",
    "\n",
    "    would be transformed to:\n",
    "\n",
    "    thank you ! this equation , is very helpful .\n",
    "\n",
    "- “retrieve a distance matrix” is a matter of coding. It also might be irrelevant: one can imagine creative answers.\n",
    "\n",
    "    becomes, if you choose to remove double quotes from the original text:\n",
    "\n",
    "    retrieve a distance matrix is a matter of coding. it also might be irrelevant : one can imagine creative answers .\n",
    "\n",
    "Note that punctuation signs (, . : !) are also represented as tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6194550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45cc342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_separated_lower(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return \" \".join(list(filter(lambda x: x not in ['“', \"”\"], tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00ff51be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'retrieve a distance matrix is a matter of coding . it also might be irrelevant : one can imagine creative answers .'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '“retrieve a distance matrix” is a matter of coding. It also might be irrelevant: one can imagine creative answers.'\n",
    "space_separated_lower(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a23e5dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df.text.apply(space_separated_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4afec4",
   "metadata": {},
   "source": [
    "## Export the resulting DataFrame into a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3df59f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "df.to_csv(\"../data/stackexchange_cleaned.csv\", quoting = csv.QUOTE_ALL, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd56820c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
